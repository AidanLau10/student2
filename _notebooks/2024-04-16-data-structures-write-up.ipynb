{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Data Structures Write Up\n",
    "comments: true\n",
    "hide: true\n",
    "layout: post\n",
    "courses: { labnb: {week: 30} }\n",
    "type: hacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures Project Requirements\n",
    "\n",
    "- Searching\n",
    "![Searching](../../../images/DataStructureSearching.png)\n",
    "Searching is the process of going through a list and finding a specific element. In this case, a list of all the user ids that match the job from the request url is being made. This list of user ids is searched through to find the first user that corresponds with the user id in the User database. Finally, the data is returned in JSON by accessing the read attribute of all the users.\n",
    "- Hashing / Dictionaries\n",
    "![Dictionary](../../../images/DataStructureDictionary.png)\n",
    "A dictionary is a collection of key-value pairs. While using Python Debugger which returns a list of Jobs, the Python object is listed on the debugger panel. This is an example of a dictionary because each job(key), lets say job 1, has values such as pay, qualification, title.\n",
    "- Algorithms\n",
    "![Algorithmns](../../../images/DataStructureAlgorithmn.png)\n",
    "An algorithmn is a process which takes multiple steps and conditions to reach a goal. THis function is meant to extract the user's userid in the cookie tab.  It splits the cookie string into an array and iterates through each cookie, removing leading spaces. If a cookie's name matches the specified name, it returns the value of that cookie. \n",
    "- Object-Oriented design\n",
    "![Object-Oriented Design](../../../images/DataStructureObject.png)\n",
    "Object-Oriented are Python classes that have methods assosicated with them. In this case, _submitApplication is a Python class which defines the endpoint of the url. Inside the class, An Application and JobUser is being made with the data extracted from the request from the frontend. \n",
    "- Collections / Lists\n",
    "![Lists](../../../images/DataStructureList.png)\n",
    "Lists are a collection of elements. When using Python Debugger, a list of JobUser objects are displayed on the debugger panel. Although this data isn't readable and sendable to return, it is an example of a list which contains elements(JobUser)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections\n",
    "\n",
    "- From VSCode using SQLite3 Editor, show your unique collection/table in database, display rows and columns in the table of the SQLite database.\n",
    "\n",
    "![Applications Table](../../../images/TableApplications.png)\n",
    "- In the applications table, it has a relationship with the jobs and users tables because users apply to jobs which is their application.\n",
    "\n",
    "![Jobs/Users Table](../../../images/TableJobsUsers.png)\n",
    "- This is a join table for jobs and users which connects which users posted or applied to a job. In the case of this project, we have a profiling system which says which jobs you applied to or which jobs you made. This join table connects users and the jobs.\n",
    "\n",
    "![Jobs Table](../../../images/TableJobs.png)\n",
    "- This is the jobs table which defines each job and their details. They have a unique id which is used later on.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- From VSCode model, show your unique code that was created to initialize table and create test data.\n",
    "\n",
    "![Initiation of Application Test Data](../../../images/TableinitApplications.png)\n",
    "![Initiation of Jobs Test Data](../../../images/tableinitJobs.png)\n",
    "![Initiation of Jobs/Users Relationship Test Data](../../../images/tableinitJobsUsers.png)\n",
    "\n",
    "- All of the initiation of the data follow a similar pattern where the object is being created with test data and then it is looped through to and the create method is defined to add it to the database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists and Dictionaries\n",
    "\n",
    "- In VSCode using Debugger, show a list as extracted from database as Python objects.\n",
    "![Jobs Breakpoint](../../../images/ListsJobsBreakpoint.png)\n",
    "\n",
    "- When hitting the jobs endpoint to get all the jobs, the json_ready line will read all the jobs in the database and the Python list will appear on the debugger side panel. This shows all the job objects queried.\n",
    "\n",
    "- In VSCode use Debugger and list, show two distinct example examples of dictionaries, show Keys/Values using debugger.\n",
    "![Job Object](../../../images/ListsJobObject.png)\n",
    "- The list in the debugger contains all the jobs by id(1,2,3,4,5,etc.) which is the key and clicking into a specific job shows the value such as the jobpostee and pay.\n",
    "![Jobs Output](../../../images/ListsJobsOutput.png)\n",
    "- This is the actual formatted output of the jobs on the frontend that takes all the objects and displays them.\n",
    "\n",
    "- Job and User Relationship\n",
    "![JobsUsers Breakpoint](../../../images/ListsJobUserBreakpoint.png)\n",
    "![JobsUsers Object](../../../images/ListsJobUserObject.png)\n",
    "- The list in the debugger are the job/user objects with unique ids and these are the keys. The values rae the userid and jobid which correspond to each other.\n",
    "\n",
    "![Applicant](../../../images/ListsApplicant.png)\n",
    "- This is a display of the job/user relationship where each job has an applicant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs and JSON\n",
    "\n",
    "- In VSCode, show Python API code definition for request and response using GET, POST, UPDATE methods. Discuss algorithmic condition used to direct request to appropriate Python method based on request method.\n",
    "\n",
    "Method: The frontend hits an endpoint(http://127.0.0.1:8064/api/job/). In the definition of the API code, the endpoint is associated with a class and a function in the class associates with the method such as GET or POST. This will run the specific Python method based on the request method. \n",
    "\n",
    "![GET Code Definition](../../../images/APIgetcodedefinition.png)\n",
    "- In the GET funtion, it checks if there is a parameter in the url which is the id. If there is an id, it queries the jobs table for the first job according to that id and returns the job. If there is no id, it will query all te jobs and return each job.\n",
    "![POST Code Definition](../../../images/APIpostcodedefinition.png)\n",
    "- In the POST function, it converts the request into JSON and gets the details of it(address, email, separationFacctor, jobid, and userid). Then, it creates the Application object with the details and it also creates the JobUser object because it ties the user's application to the job they posted. It returns the application if it is successful and returns an error message if not successful.\n",
    "![PUT Code Definition](../../../images/APIputcodedefinition.png)\n",
    "- In the PUT function, it gets the id in the parameter of the request and queries the jobs table for the first job that corresponds to that id. Then, it converts the request into JSON and gets the details of it(title, description, qualification, pay, field, and location). It usees these details to apply the update method which will change any new data from the existing job.\n",
    "\n",
    "- In VSCode, show algorithmic conditions used to validate data on a POST condition.\n",
    "![POST Code Definition](../../../images/APIpostcodedefinition.png)\n",
    "\n",
    "- The code validates data on the POST condition by getting the body in JSON form and then creating the object. If it is unable to create the object because some data is wrong, it will send an error message.\n",
    "\n",
    "- In Postman, show URL request and Body requirements for GET, POST, and UPDATE methods.In Postman, show the JSON response data for 200 success conditions on GET, POST, and UPDATE methods.\n",
    "\n",
    "![Postman GET All Jobs](../../../images/APIgetPostman.png)\n",
    "\n",
    "- Since this is a GET request, no body is needed and it will return all the jobs. If I do a parameter such as the id, it will return that specific job with that specific id.\n",
    "\n",
    "\n",
    "![Postman GET Old Job Before PUT](../../../images/APIgetPostmanOldJob.png)\n",
    "- This is what is returned before the job is updated\n",
    "![Postman PUT Body, Request, and Response](../../../images/APIputPostman.png)\n",
    "- This is the put request which contains all the necessary job details to update the job. If there is a missing field, it will return an error.\n",
    "![Postman GET Old Job After PUT](../../../images/APIgetPostmanUpdatedJob.png)\n",
    "- This is the is returned after the job is updated\n",
    "\n",
    "![Postman POST Body, Request, and Response](../../../images/APIsubmitapplication.png)\n",
    "\n",
    "\n",
    "- In Postman, show the JSON response for error for 400 when missing body on a POST request.\n",
    "![Postman Missing Body POST Error](../../../images/APIposterror.png)\n",
    "\n",
    "- In the POST request, I am missing the required address field. Since the missing address field makes it unable to created the application object and throws an error for a None object.\n",
    "\n",
    "- In Postman, show the JSON response for error for 404 when providing an unknown user ID to a UPDATE request.\n",
    "![Postman PUT Error](../../../images/APIputerror.png)\n",
    "\n",
    "- In the parameter of the request url, the id is 21. However, there isn't a job associated with that id(since there aren't 21 jobs), so it throws and error when trying to find the job and updating it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontend\n",
    "\n",
    "- In Chrome inspect, show response of JSON objects from fetch of GET, POST, and UPDATE methods.\n",
    "![Frontend Edit Job](../../../images/FrontendEditJob.png)\n",
    "- This is the PUT method which updates the details of the job and the successful response will return the Job object.\n",
    "![Frontend Get Jobs](../../../images/FrontendGetJobs.png)\n",
    "- This is the GET method which returns all the jobs and their details and the frontend will display them by iterating over each job.\n",
    "![Frontend Submit Application](../../../images/FrontendSubmitApplication.png)\n",
    "- This is the POST method which will create the application and correlate the job with the user. The most important data returned is the user id that correlates with the job id to connect them.\n",
    "\n",
    "- In the Chrome browser, show a demo (GET) of obtaining an Array of JSON objects that are formatted into the browsers screen.\n",
    "    ![Frontend Jobs](../../../images/FrontendJobs.png)\n",
    "    - The array of JSON objects that are formatted are the jobs and their details which are iterated over and each job has a row with multiple columns.\n",
    "\n",
    "    - In JavaScript code, describe fetch and method that obtained the Array of JSON objects.\n",
    "    - In JavaScript code, show code that performs iteration and formatting of data into HTML.\n",
    "    ![Frontend Fetch Data](../../../images/FrontendFetchData.png)\n",
    "    - The fetch has a GET method and hits the /api/job/ endpoint. If the response is unsuccesful, it will return an error and the error will be populated in the table. If the response is ok, then it is converted to JSON and for each JSON list in the dictionary, it will create a row with the id, title, description, field, etc and append it to the table. Then it will apply the filterJobs function which will apply the desired filters such as search bar, field, and location. \n",
    "\n",
    "- In the Chrome browser, show a demo (POST or UPDATE) gathering and sending input and receiving a response that show update. Repeat this demo showing both success and failure.\n",
    "    ![Frontend Login Code](../../../images/FrontendLoginCode.png)\n",
    "\n",
    "    - The user id and password's values are gathered and prepared as a JSON body in the POST request. Then, it uses the headers to fetch the authentication url.\n",
    "\n",
    "    - In JavaScript code, show and describe code that handles success. Describe how code shows success to the user in the Chrome Browser screen.\n",
    "    ![Frontend Successful Login](../../../images/FrontendSuccessfulLogin.png)   \n",
    "    - If the response is successful, the response is converted to json and then the user is assigned a cookie with the response and sent to their profile page which lets them know they are successful.\n",
    "    - In JavaScript code, show and describe code that handles failure. Describe how the code shows failure to the user in the Chrome Browser screen.\n",
    "    ![Frontend Error Login](../../../images/FrontendErrorLogin.png)\n",
    "    - If the user tries to login with invalid data, nothing will occur when they click on the login button, letting them know they failed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "![AI Extra](../../../images/AIextra.png)\n",
    "\n",
    "\n",
    "- First, the dataset is read by pandas and then a copy of it is created. Next, unnecessary columns such as age, accessibility, mainbranch, etc are dropped and replaced with True values. More cleaning is done by dropping the unnamed column which came with the original dataset and then dropping any null values. A scaler is applied to the years coded because people can be coding for 0-20 years which is a wide range and should be scaled. After that, gender and employment are applied lambas because a gender can either be male or female employment can either be not employed or employed. The last step in cleaning the data is encoding the Education Level because there can be multiple education levels and creating a column for each with a binary as true or false for if a row has that data helps to add to the Logistic Regression. The last step is splitting the data into training and testing sets with Employed as the target value and applying the Logistic Regression model.\n",
    "\n",
    "- Linear regression is used to model the relationship between two continuous variables. It takes data points and makes a line of best fit to predict future values.\n",
    "- Decision trees use nodes with multiple layers to classify answers as true or false / yes or no and then reach a final conclusion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
